COVIDSTREAM: COVID-19 Data Pipeline

Overview

COVIDSTREAM addresses the critical challenge of efficiently integrating and analyzing large-scale COVID-19 datasets. The project enables seamless evaluation of post-pandemic trends, providing insights to enhance preparedness for future health crises. A scalable ETL pipeline was developed to streamline data ingestion, transformation, and analysis.

Technologies Used

AWS Services: S3, Glue, Redshift

Python: Pandas, boto3

SQL: Redshift Querying


Key Features


Built a robust Extract, Transform, Load (ETL) pipeline to process large-scale COVID-19 datasets.

S3: Acted as the storage layer for raw COVID-19 data.

Glue: Orchestrated the ETL pipeline to automate data transformation and loading.

Redshift: Optimized for storing and querying the cleaned data using SQL.

Data Transformation and Cleaning

Leveraged Python (Pandas) to transform, clean, and prepare raw COVID-19 data for analysis.
Ensured data consistency and accuracy for downstream querying.

Automation and Efficiency

Utilized boto3 for seamless integration between AWS services.
Enabled efficient orchestration of the pipeline with AWS Glue for minimal manual intervention.
